# Settings for instantiating the model architecture/checkpoint behavior.
model: # Model Settings
  model_type: "cond_px_dif" # Model type (only conditional diffusion is supported).
  resume_checkpoint: false #"logs/2026-02-11_17-11-24/best.ckpt"  # false/null starts from scratch; set to a .ckpt path to continue training.
  load_checkpoint: false #"logs/2026-02-11_17-11-24/best.ckpt"  # false/null disables warm start; set to a .ckpt path to load model state_dict only (no PL optimizer/trainer state).
  generated_channels: 3 # Predict 3-band temperature profile target y.
  condition_channels: 5 # EO (1) + corrupted temp channels x (3) + valid mask (1).
  condition_mask_channels: 1 # One valid-mask channel is concatenated to the model condition.
  condition_include_eo: true # Include batch["eo"] as extra condition channel.
  condition_use_valid_mask: true # Use valid_mask as conditioning input in addition to EO + x.
  clamp_known_pixels: false # If true, inpainting-style sampling clamps known pixels each diffusion step for generation stability.
  mask_loss_with_valid_pixels: true # If true, loss is computed over missing pixels (1-valid_mask), with optional land/ocean gating.
  training_objective:
    mode: "x_holdout_sparse" # "standard" keeps y-supervision; "x_holdout_sparse" hides holdout_fraction of observed x and supervises only those held-out pixels.
    holdout_fraction: 0.2 # Fraction of observed x pixels held out from condition input in x_holdout_sparse mode.
    deterministic_val_mask: true # If true, validation holdout masks are deterministic per sample (from date/coords).
    dump_val_reconstruction:
      enabled: false # If true, writes full per-step validation reconstruction images to output_dir.
      output_dir: "temp/val_step_reconstruction" # Local folder for validation-step reconstruction dumps.
      max_samples: 1 # Number of samples dumped per selected validation batch.
      only_first_batch: true # Restrict dumping to the first validation batch to control runtime/IO.
  parameterization: "x0" # Diffusion training target: "epsilon" (noise) or "x0" (clean sample).
  log_intermediates: true # Default for validation denoising intermediate logging; training.validation_sampling.log_intermediates overrides this.
  post_process:
    gaussian_blur:
      enabled: false # If true, apply a small Gaussian blur to denormalized predictions at final post-process.
      sigma: 0.5 # Small blur strength (standard deviation in pixels).
      kernel_size: 3 # Odd kernel size; even values are auto-adjusted to the next odd number.

  coord_conditioning:
    enabled: true # Enable patch-center coordinate conditioning via FiLM.
    encoding: "unit_sphere" # "unit_sphere", "sincos", or "raw".
    include_date: true # If true, also encode batch["date"] (YYYYMMDD) together with coords.
    date_encoding: "day_of_year_sincos" # Current option: non-leap day-of-year sin/cos with denominator 365.
    embed_dim: null # If null, defaults to unet.dim.

  unet: # Denoiser backbone (ConvNeXt U-Net) settings.
    dim: 64 # Base channel width of U-Net. Use soemthing like dim=96 with more input bands
    dim_mults: [1, 2, 4, 8] # Per-stage width multipliers; length controls U-Net depth.
    with_time_emb: true # Enable timestep embeddings in the denoiser.
    output_mean_scale: false # Optional output mean correction used by some diffusion variants.
    residual: false # If true, predicts a residual added to input.
